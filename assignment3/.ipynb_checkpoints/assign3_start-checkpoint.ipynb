{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 3**\n",
    "\n",
    "_This notebook contains simple starter code to show loading and displaying a pair of test images and the associated flow._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted helper routine from Aurelien Geron: Hand-on Machine Learning with Scikit-learn & Tensorflow.\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage \n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"./\"\n",
    "NB_ID = \"assignment3\"\n",
    "\n",
    "# create the directory if it does not exist\n",
    "os.makedirs(os.path.join(PROJECT_ROOT_DIR, \"images\", NB_ID), exist_ok = True)\n",
    "        \n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", NB_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the image pairs and the corresponding flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load(os.path.join(PROJECT_ROOT_DIR, NB_ID, 'rot_images_train.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flows = np.load(os.path.join(PROJECT_ROOT_DIR, NB_ID, 'rot_flows_train.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of training images: {0} x {1} x {2} x {3}\\n'.format(*train_images.shape))\n",
    "print('Size of flow results: {0} x {1} x {2} x {3}\\n'.format(*train_flows.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RGB images, we need the channels last, e.g., 64x64x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_RGB(img_arr, img_no, seq_no ): \n",
    "    test = np.zeros(img_arr.shape[2:]+(3,))  \n",
    "    test[:,:,2] = img_arr[img_no,0+3*seq_no,:,:] \n",
    "    test[:,:,1] = img_arr[img_no,1+3*seq_no,:,:] \n",
    "    test[:,:,0] = img_arr[img_no,2+3*seq_no,:,:]\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Greyscale(img_arr, img_no, seq_no ): \n",
    "    return img_arr[img_no,seq_no,:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 100\n",
    "\n",
    "fig, axes = plt.subplots(2, 2,figsize=(8,8))\n",
    "axes[0, 0].imshow(make_RGB(train_images, img_num, 0 ))\n",
    "axes[0, 0].set_title('Start')    \n",
    "\n",
    "axes[0, 1].imshow(make_RGB(train_images, img_num, 1 ))\n",
    "axes[0, 1].set_title('Goal')    \n",
    "\n",
    "# Find the min and max of the flow.\n",
    "from matplotlib import colors\n",
    "fl_min = np.min(train_flows[img_num,0:2,:,:])\n",
    "fl_max = np.max(train_flows[img_num,0:2,:,:])\n",
    "fl_norm = colors.Normalize(vmin=fl_min, vmax=fl_max)\n",
    "\n",
    "im = axes[1, 0].imshow(make_Greyscale(train_flows, img_num, 0 ))\n",
    "im.set_norm(fl_norm)\n",
    "axes[1, 0].set_title('Flow in x')\n",
    "fig.colorbar(im,ax=axes[1, 0])\n",
    "\n",
    "im = axes[1, 1].imshow(make_Greyscale(train_flows, img_num, 1 ))\n",
    "im.set_norm(fl_norm)\n",
    "axes[1, 1].set_title('Flow in y')\n",
    "fig.colorbar(im,ax=axes[1, 1])\n",
    "\n",
    "save_fig(\"example_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.load(os.path.join(PROJECT_ROOT_DIR, NB_ID, 'rot_images_test.npy'))\n",
    "test_flows = np.load(os.path.join(PROJECT_ROOT_DIR, NB_ID, 'rot_flows_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetInputSet(raw_images, concat_last_axis = True):\n",
    "    \"\"\"\n",
    "    Function: concatenate each pair images together as input.\n",
    "    \"\"\"\n",
    "    hm_images = len(raw_images)\n",
    "    dataset = []\n",
    "    for i in range(hm_images):\n",
    "        img_start = make_RGB(raw_images, i, 0)\n",
    "        img_goal = make_RGB(raw_images, i, 1)\n",
    "        # concatenate on the last dimension\n",
    "        if concat_last_axis:\n",
    "            imgs_concat = np.concatenate([img_start, img_goal], axis = -1)\n",
    "        else:\n",
    "            imgs_concat = np.concatenate([img_start, img_goal], axis = 0)\n",
    "        dataset.append(imgs_concat)\n",
    "    dataset = np.array(dataset)\n",
    "    return dataset\n",
    "\n",
    "def GetOutputset(raw_gts, concat_last_axis = True):\n",
    "    \"\"\"\n",
    "    Function: get the corresponding ground truth vectors.\n",
    "    \"\"\"\n",
    "    hm_gts = len(raw_gts)\n",
    "    dataset = []\n",
    "    for i in range(hm_gts):\n",
    "        # expand the last dimension for concatenating\n",
    "        gt_x = np.expand_dims(make_Greyscale(raw_gts, i, 0), axis=-1)\n",
    "        gt_y = np.expand_dims(make_Greyscale(raw_gts, i, 1), axis=-1)\n",
    "        # concatenate on the last dimension\n",
    "        if concat_last_axis:\n",
    "            gt_concat = np.concatenate([gt_x, gt_y], axis = -1)\n",
    "        else:\n",
    "            gt_concat = np.concatenate([gt_x, gt_y], axis = 0)\n",
    "        dataset.append(gt_concat)\n",
    "    dataset = np.array(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShuffleIndex(data):\n",
    "    \"\"\"\n",
    "    Function: return shuffled index\n",
    "    \"\"\"\n",
    "    shuffle_index = np.arange(len(data))\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    return shuffle_index\n",
    "\n",
    "def Shuffle(data_in, data_out):\n",
    "    \"\"\"\n",
    "    Function: shuffle dataset\n",
    "    \"\"\"\n",
    "    shuffle_index = ShuffleIndex(data_in)\n",
    "    data_in = data_in[shuffle_index]\n",
    "    data_out = data_out[shuffle_index]\n",
    "    return data_in, data_out\n",
    "\n",
    "train_in = GetInputSet(train_images)\n",
    "train_out = GetOutputset(train_flows)\n",
    "train_in, train_out = Shuffle(train_in, train_out)\n",
    "\n",
    "test_in = GetInputSet(test_images)\n",
    "test_out = GetOutputset(test_flows)\n",
    "\n",
    "print(\"Shape of the training images:\\t\", train_in.shape)\n",
    "print(\"Shape of the training flows:\\t\",train_out.shape)\n",
    "print(\"Shape of the test images:\\t\",test_in.shape)\n",
    "print(\"Shape of the test flows:\\t\",test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "# import tf.keras\n",
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "import tensorflow.keras.regularizers as R\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def Loss(y_true, y_pred):\n",
    "    weight_vector = tf.where(y_true==0., 0.2*K.ones_like(y_true), 0.8*K.ones_like(y_true))\n",
    "    # return K.mean(K.square(y_true - y_pred)*weight_vector)\n",
    "    return K.mean(K.square(y_pred - y_true))\n",
    "\n",
    "def Metrics(y_true, y_pred):\n",
    "    # weight_vector = tf.where(y_true==0., 0.2*K.ones_like(y_true), 0.8*K.ones_like(y_true))\n",
    "    value = K.abs(y_true - y_pred)\n",
    "    false_pred = K.cast(K.greater(value, 1e-3), 'float32') # * weight_vector\n",
    "    whole_ones = K.ones_like(value) # * weight_vector\n",
    "    return K.sum(1. - false_pred) / K.sum(whole_ones)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(L.Conv2D(64, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                   activation='relu', input_shape=(64, 64, 6)))\n",
    "model.add(L.Conv2D(128, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu'))\n",
    "model.add(L.Conv2D(256, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                   activation='relu'))\n",
    "model.add(L.Conv2D(512, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu'))\n",
    "model.add(L.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu'))\n",
    "model.add(L.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu'))\n",
    "model.add(L.Conv2D(2, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                   activation='linear'))\n",
    "\n",
    "# GPU memory management\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, min_lr=1e-5)\n",
    "model.compile(loss=Loss, optimizer=Adam(lr=0.0008), metrics=[Metrics])\n",
    "\n",
    "model.fit(train_in, train_out, batch_size=10, epochs=15,\n",
    "#             validation_data=(test_in, test_out),\n",
    "            callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_in, test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_number = 101\n",
    "\n",
    "test_example_images = np.expand_dims(test_in[random_test_number], axis=0)\n",
    "test_example_gt = test_out[random_test_number]\n",
    "test_example_pred = model.predict(test_example_images)\n",
    "test_example_pred = np.squeeze(test_example_pred)\n",
    "test_example_gt = np.squeeze(test_example_gt)\n",
    "print(test_example_pred.shape)\n",
    "print(test_example_gt.shape)\n",
    "\n",
    "fl_min = np.min(test_example_gt)\n",
    "fl_max = np.max(test_example_gt)\n",
    "fl_norm = colors.Normalize(vmin=fl_min, vmax=fl_max)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2,figsize=(8,8))\n",
    "\n",
    "print(\"Prediction and ground truth of the example images in the test set.\")\n",
    "im = axes[0, 0].imshow(test_example_pred[..., 0])\n",
    "# im = axes[0, 0].imshow(test_example_pred[:len(test_example_pred)//2, :])\n",
    "im.set_norm(fl_norm)\n",
    "axes[0, 0].set_title('Prediction: Flow in x')\n",
    "fig.colorbar(im,ax=axes[0, 0])\n",
    "\n",
    "im = axes[0, 1].imshow(test_example_pred[..., 1])\n",
    "# im = axes[0, 1].imshow(test_example_pred[len(test_example_pred)//2:, :])\n",
    "im.set_norm(fl_norm)\n",
    "axes[0, 1].set_title('Prediction: Flow in y')\n",
    "fig.colorbar(im,ax=axes[0, 1])\n",
    "\n",
    "im = axes[1, 0].imshow(test_example_gt[..., 0])\n",
    "# im = axes[1, 0].imshow(test_example_gt[:len(test_example_gt)//2, ...])\n",
    "im.set_norm(fl_norm)\n",
    "axes[1, 0].set_title('Ground Truth: Flow in x')\n",
    "fig.colorbar(im,ax=axes[1, 0])\n",
    "\n",
    "im = axes[1, 1].imshow(test_example_gt[..., 1])\n",
    "# im = axes[1, 1].imshow(test_example_gt[len(test_example_gt)//2:, ...])\n",
    "im.set_norm(fl_norm)\n",
    "axes[1, 1].set_title('Ground Truth: Flow in y')\n",
    "fig.colorbar(im,ax=axes[1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_train_images = np.load(os.path.join(PROJECT_ROOT_DIR, NB_ID, 'mix_images_train.npy'))\n",
    "mix_train_flows = np.load(os.path.join(PROJECT_ROOT_DIR, NB_ID, 'mix_flows_train.npy'))\n",
    "mix_test_images = np.load(os.path.join(PROJECT_ROOT_DIR, NB_ID, 'mix_images_test.npy'))\n",
    "mix_test_flows = np.load(os.path.join(PROJECT_ROOT_DIR, NB_ID, 'mix_flows_test.npy'))\n",
    "\n",
    "mix_train_in = GetInputSet(mix_train_images, concat_last_axis=True)\n",
    "mix_train_out = GetOutputset(mix_train_flows, concat_last_axis=True)\n",
    "mix_train_in, mix_train_out = Shuffle(mix_train_in, mix_train_out)\n",
    "\n",
    "mix_test_in = GetInputSet(mix_test_images, concat_last_axis=True)\n",
    "mix_test_out = GetOutputset(mix_test_flows, concat_last_axis=True)\n",
    "\n",
    "rot_train_in = GetInputSet(train_images, concat_last_axis=True)\n",
    "rot_train_out = GetOutputset(train_flows, concat_last_axis=True)\n",
    "rot_train_in, rot_train_out = Shuffle(rot_train_in, rot_train_out)\n",
    "\n",
    "rot_test_in = GetInputSet(test_images, concat_last_axis=True)\n",
    "rot_test_out = GetOutputset(test_flows, concat_last_axis=True)\n",
    "\n",
    "print(\"Shape of the rotation training images:\\t\", rot_train_in.shape)\n",
    "print(\"Shape of the rotation training flows:\\t\",rot_train_out.shape)\n",
    "print(\"Shape of the rotation test images:\\t\",rot_test_in.shape)\n",
    "print(\"Shape of the rotation test flows:\\t\",rot_test_out.shape)\n",
    "\n",
    "print(\"Shape of the mixed training images:\\t\", mix_train_in.shape)\n",
    "print(\"Shape of the mixed training flows:\\t\",mix_train_out.shape)\n",
    "print(\"Shape of the mixed test images:\\t\",mix_test_in.shape)\n",
    "print(\"Shape of the mixed test flows:\\t\",mix_test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.applications as App\n",
    "K.clear_session()\n",
    "\n",
    "base_model = App.vgg16.VGG16(input_shape=(64, 64, 3), include_top=False, weights='imagenet')\n",
    "vgg16_layers = Sequential()\n",
    "for layer in base_model.layers[:14]:\n",
    "    vgg16_layers.add(layer)\n",
    "\n",
    "base_model.trainable = False\n",
    "vgg16_layers.trainable = False\n",
    "vgg16_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = L.Conv2D(64, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                   activation='relu', input_shape=(64, 64, 6))\n",
    "header2 = L.Conv2D(3, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                   activation='relu')\n",
    "\n",
    "regression_layer1 = L.Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu')\n",
    "regression_layer2 = L.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu')\n",
    "regression_layer3 = L.Conv2DTranspose(128 , (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu')\n",
    "regression_layer4 = L.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu')\n",
    "regression_layer5 = L.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu')\n",
    "regression_layer6 = L.Conv2D(1, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                   activation='linear')\n",
    "regression_layer7 = L.Conv2DTranspose(2, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                   activation='linear')\n",
    "\n",
    "vgg16_based_model = Sequential([header, header2, vgg16_layers, regression_layer2,\n",
    "                                regression_layer3, regression_layer4, regression_layer7])\n",
    "\n",
    "vgg16_based_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, min_lr=1e-5)\n",
    "\n",
    "vgg16_based_model.compile(loss=Loss, optimizer=Adam(lr=0.0008), metrics=[Metrics])\n",
    "vgg16_based_model.fit(rot_train_in, rot_train_out, batch_size=10, epochs=15,\n",
    "#             validation_data=(test_in, test_out),\n",
    "            callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_number = 101\n",
    "\n",
    "rot_test_example_images = np.expand_dims(rot_test_in[random_test_number], axis=0)\n",
    "rot_test_example_gt = rot_test_out[random_test_number]\n",
    "rot_test_example_pred = vgg16_based_model.predict(rot_test_example_images)\n",
    "rot_test_example_pred = np.squeeze(rot_test_example_pred)\n",
    "rot_test_example_gt = np.squeeze(rot_test_example_gt)\n",
    "\n",
    "rot_fl_min = np.min(rot_test_example_gt)\n",
    "rot_fl_max = np.max(rot_test_example_gt)\n",
    "rot_fl_norm = colors.Normalize(vmin=fl_min, vmax=fl_max)\n",
    "\n",
    "vgg16_based_model.evaluate(rot_test_in, rot_test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "base_model = App.vgg16.VGG16(input_shape=(128, 64, 3), include_top=False, weights='imagenet')\n",
    "vgg16_layers = Sequential()\n",
    "for layer in base_model.layers[:14]:\n",
    "    vgg16_layers.add(layer)\n",
    "\n",
    "base_model.trainable = False\n",
    "vgg16_layers.trainable = False\n",
    "\n",
    "header = L.Conv2D(64, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                   activation='relu', input_shape=(64, 64, 6))\n",
    "header2 = L.Conv2D(3, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                   activation='relu')\n",
    "\n",
    "regression_layer1 = L.Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu')\n",
    "regression_layer2 = L.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu')\n",
    "regression_layer3 = L.Conv2DTranspose(128 , (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu')\n",
    "regression_layer4 = L.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu')\n",
    "regression_layer5 = L.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                   activation='relu')\n",
    "regression_layer6 = L.Conv2D(1, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                   activation='linear')\n",
    "regression_layer7 = L.Conv2DTranspose(2, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                   activation='linear')\n",
    "\n",
    "vgg16_based_model = Sequential([header, header2, vgg16_layers, regression_layer2,\n",
    "                                regression_layer3, regression_layer4, regression_layer7])\n",
    "\n",
    "vgg16_based_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, min_lr=1e-5)\n",
    "\n",
    "vgg16_based_model.compile(loss=Loss, optimizer=Adam(lr=0.0008), metrics=[Metrics])\n",
    "vgg16_based_model.fit(mix_train_in, mix_train_out, batch_size=10, epochs=15,\n",
    "#             validation_data=(test_in, test_out),\n",
    "            callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_test_example_images = np.expand_dims(mix_test_in[random_test_number], axis=0)\n",
    "mix_test_example_gt = mix_test_out[random_test_number]\n",
    "mix_test_example_pred = vgg16_based_model.predict(mix_test_example_images)\n",
    "mix_test_example_pred = np.squeeze(mix_test_example_pred)\n",
    "mix_test_example_gt = np.squeeze(mix_test_example_gt)\n",
    "\n",
    "mix_fl_min = np.min(mix_test_example_gt)\n",
    "mix_fl_max = np.max(mix_test_example_gt)\n",
    "mix_fl_norm = colors.Normalize(vmin=fl_min, vmax=fl_max)\n",
    "\n",
    "vgg16_based_model.evaluate(mix_test_in, mix_test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(12,7))\n",
    "\n",
    "print(\"Prediction and ground truth of the example images in the test set.\")\n",
    "im = axes[0, 0].imshow(rot_test_example_pred[..., 0])\n",
    "# im = axes[0, 0].imshow(rot_test_example_pred[:len(rot_test_example_pred)//2, :])\n",
    "im.set_norm(rot_fl_norm)\n",
    "axes[0, 0].set_title('Rotation Prediction in x')\n",
    "# fig.colorbar(im,ax=axes[0, 0])\n",
    "\n",
    "im = axes[0, 1].imshow(rot_test_example_pred[..., 1])\n",
    "# im = axes[0, 1].imshow(rot_test_example_pred[len(rot_test_example_pred)//2:, :])\n",
    "im.set_norm(rot_fl_norm)\n",
    "axes[0, 1].set_title('Rotation Prediction in y')\n",
    "# fig.colorbar(im,ax=axes[0, 1])\n",
    "\n",
    "im = axes[1, 0].imshow(rot_test_example_gt[..., 0])\n",
    "# im = axes[1, 0].imshow(rot_test_example_gt[:len(rot_test_example_gt)//2, ...])\n",
    "im.set_norm(rot_fl_norm)\n",
    "axes[1, 0].set_title('Rotation Ground Truth in x')\n",
    "# fig.colorbar(im,ax=axes[1, 0])\n",
    "\n",
    "im = axes[1, 1].imshow(rot_test_example_gt[..., 1])\n",
    "# im = axes[1, 1].imshow(rot_test_example_gt[len(rot_test_example_gt)//2:, ...])\n",
    "im.set_norm(rot_fl_norm)\n",
    "axes[1, 1].set_title('Rotation Ground Truth in y')\n",
    "# fig.colorbar(im,ax=axes[1, 1])\n",
    "\n",
    "#############################################################\n",
    "im = axes[0, 2].imshow(mix_test_example_pred[..., 0])\n",
    "# im = axes[0, 2].imshow(mix_test_example_pred[:len(mix_test_example_pred)//2, :])\n",
    "im.set_norm(mix_fl_norm)\n",
    "axes[0, 2].set_title('Mixed Prediction in x')\n",
    "# fig.colorbar(im,ax=axes[0, 2])\n",
    "\n",
    "im = axes[0, 3].imshow(mix_test_example_pred[..., 1])\n",
    "# im = axes[0, 3].imshow(mix_test_example_pred[len(mix_test_example_pred)//2:, :])\n",
    "im.set_norm(mix_fl_norm)\n",
    "axes[0, 3].set_title('Mixed Prediction in y')\n",
    "# fig.colorbar(im,ax=axes[0, 3])\n",
    "\n",
    "im = axes[1, 2].imshow(mix_test_example_gt[..., 0])\n",
    "# im = axes[1, 2].imshow(mix_test_example_gt[:len(mix_test_example_gt)//2, ...])\n",
    "im.set_norm(mix_fl_norm)\n",
    "axes[1, 2].set_title('Mixed Ground Truth in x')\n",
    "# fig.colorbar(im,ax=axes[1, 2])\n",
    "\n",
    "im = axes[1, 3].imshow(mix_test_example_gt[..., 1])\n",
    "# im = axes[1, 3].imshow(mix_test_example_gt[len(mix_test_example_gt)//2:, ...])\n",
    "im.set_norm(mix_fl_norm)\n",
    "axes[1, 3].set_title('Mixed Ground Truth in y')\n",
    "# fig.colorbar(im,ax=axes[1, 3])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransferInputData(input_data):\n",
    "    \"\"\"\n",
    "    Function: transfer training data to the format we want.\n",
    "    \"\"\"\n",
    "    return [input_data[..., :3], input_data[..., 3:]]\n",
    "\n",
    "rot_train_in_sep = TransferInputData(rot_train_in)\n",
    "rot_test_in_sep = TransferInputData(rot_test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# import tensorflow.keras.backend as K\n",
    "# import tensorflow.keras.layers as L\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "# import tensorflow.keras.regularizers as R\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# def Loss(y_true, y_pred):\n",
    "#     weight_vector = tf.where(y_true==0., 0.2*K.ones_like(y_true), 0.8*K.ones_like(y_true))\n",
    "#     # return K.mean(K.square(y_true - y_pred)*weight_vector)\n",
    "#     return K.mean(K.square(y_pred - y_true))\n",
    "# def Metrics(y_true, y_pred):\n",
    "#     # weight_vector = tf.where(y_true==0., 0.2*K.ones_like(y_true), 0.8*K.ones_like(y_true))\n",
    "#     value = K.abs(y_true - y_pred)\n",
    "#     false_pred = K.cast(K.greater(value, 1e-3), 'float32') # * weight_vector\n",
    "#     whole_ones = K.ones_like(value) # * weight_vector\n",
    "#     return K.sum(1. - false_pred) / K.sum(whole_ones)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "def FirstTwoLayers(x):\n",
    "    x = L.Conv2D(64, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                               activation='relu')(x)\n",
    "    x = L.Conv2D(128, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                               activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "def NonSeqModel(input_start, input_goal):\n",
    "    feature_start = FirstTwoLayers(input_start)\n",
    "    feature_goal = FirstTwoLayers(input_goal)\n",
    "\n",
    "    x = L.Concatenate()([feature_start, feature_goal])\n",
    "    x = L.Conv2D(256, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                       activation='relu')(x)\n",
    "    x = L.Conv2D(512, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                       activation='relu')(x)\n",
    "    x = L.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                       activation='relu')(x)\n",
    "    x = L.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', \\\n",
    "                       activation='relu')(x)\n",
    "    x = L.Conv2D(2, (3, 3), strides=(1, 1), padding='same', \\\n",
    "                       activation='linear')(x)\n",
    "    return Model(inputs=[input_start, input_goal], outputs=x)\n",
    "\n",
    "\n",
    "model_input_start = L.Input(shape=(64,64,3))\n",
    "model_input_goal = L.Input(shape=(64,64,3))\n",
    "\n",
    "nonseqentialModel = NonSeqModel(model_input_start, model_input_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU memory management\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, min_lr=1e-5)\n",
    "\n",
    "model.compile(loss=Loss, optimizer=Adam(lr=0.0008), metrics=[Metrics])\n",
    "\n",
    "model.fit(train_in, train_out, batch_size=10, epochs=15,\n",
    "#             validation_data=(test_in, test_out),\n",
    "            callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
